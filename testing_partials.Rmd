---
title: "Reviewing Functions for Extracting Partials from GAMs"
output: html_notebook
---

# Introduction
In this notebook, I explore various approaches to creating plots of the marginal
effects of GAM models. I started with some simple internet searches, replicating 
their methods, and then explored some alternatives that came to light.

# Load Packages
```{r}
library(tidyverse)
library(mgcv)
library(ggeffects)
# library(emmeans)   # probably autoloaded by ggeffects, not called directly
```
# Set Graphics Theme
This sets `ggplot()`graphics for no background, no grid lines, etc. in a clean
format suitable for (some) publications.

```{r set_theme}
theme_set(theme_classic())
```

# Part 1: Simple Residual Plot

# Source
The following code is based on the helpful code snippets found 
[here](http://zevross.com/blog/2014/09/15/recreate-the-gam-partial-regression-smooth-plots-from-r-package-mgcv-with-a-little-style/])
and especially 
[here](https://gist.github.com/smbache/345ec35bea3a104bc3b4).

I have translated those examples to `ggplot()` and the tidyverse, and followed
my preferred coding style, which avoids the "T" pipe, and instead uses explicit 
intermediate variables.  That makes it easier to annotate steps and explain the
underlying logic.

# Load Data
```{r}
source <- "http://zevross.com/blog/wp-content/uploads/2014/08/chicago-nmmaps.csv"

the_data <- read.csv(source, as.is = TRUE) %>%
  mutate(date = as.Date(date)) %>%
  filter(date > as.Date("1996-12-31")) %>%
  mutate(year = substring(date, 1, 4))
the_data
```

# Run Simple GAM
```{r}
thegam <- gam(o3 ~ s(temp), data = the_data)
```

# Default Plot
We add `residuals = TRUE` to add the background points.

```{r}
plot(thegam, residuals = TRUE, main="Yuck, not a nice plot")
```

# Rolling Our Own Plot with `ggplot()`

The approach is based on calculating predicted values and related residuals
manually, and then assembling a plot by hand.

## Calculate Predicted Values
Here we calculate predicted values on a grid by temperature.  This allows us to
draft a nice prediction plot, but so far it is not a partials plot.

Note that by using `predict()` here, we are displaying conditional means, not 
marginal means.  Here that makes no difference, but it will matter with other
models.  An alternative is to use `emmeans()` to calculate predicted values 
along the margin, and plot those.

```{r}
t <- data.frame(temp = seq(min(the_data$temp), max(the_data$temp), length = 300))
p <-  predict(
        thegam
      , type    = "terms"
      , newdata = t
      , se.fit  = TRUE
    )
p <- as_tibble(p) %>% mutate(temp = t$temp)
rm(t)
```

## Calculating Marginal Residuals
We also need to generate the correct values for the background points. We
calculate the points by providing the sum of predicted values based only on the
`temp` term and adding the (working) residuals.  I also show the raw observations
in the data frame, to make the point that the correct background points are 
NOT the same as the original data.

```{r}
background <- predict(thegam, type = "terms") + residuals(thegam)
attributes(background) <- NULL
background <- tibble(temp = the_data$temp, background = background, raw = the_data$o3)
head(background)
```

## Generate a Plot
Here we diverge from the source material by relying on ggplot, not `R`'s default
`plot*()` function.

```{r} 
plt <- ggplot(p, aes(temp, fit)) +
  geom_ribbon(aes(ymin = fit - 1.96*se.fit, ymax = fit + 1.96*se.fit), 
              color = 'grey', alpha = 0.2, lty = 0) +
  geom_line(lwd = .5)+
  geom_point(data = background, mapping = aes(temp, background ),
             pch = 16, col = rgb(0, 0, 1, 0.25), size = 0.5) +
  geom_rug(data = background, mapping = aes(x = temp, y = NULL)) +
  
 
  xlim(-3, 90) +
  ylim (-20, 30) +
  ggtitle("Ahhh, definitely better") +
  ylab (paste("s(temp,", round(sum(thegam$edf[-1]),2), ")", sep = ""))
plt
```

The vertical label duplicates the convention in the `plot()` method for GAMs in
`mgcv`.  The numerical value is a measure of the total effective degrees of 
freedom of the GAM fit.  This is based on dropping the first smoothed term, 
which is for the intercept, and summing the effective degrees of freedom for 
each of the GAM spline terms.

Unfortunately, if we do this for our plots, with multiple predictors, we will
have to be careful to allocate the right number of values from the `*.efd` 
vector for each predictor, which will complicate genearizable coding.

```{r}
thegam$edf
class(thegam$edf)
sum(thegam$edf[-1])
```

# Extend That to Multiple Predictors
Our actual use case is for generating multiple plots for the different
predictors in a multi-variate GAM.  We need to develop this logic for when we
have multiple predictors.

Here we work it up just one more step of complexity, by generating a model with
two predictors.

## A Naive Model
```{r}
thegam <- gam(o3 ~ s(temp, k = 5) +s(dewpoint, k = 5), data = the_data)
```

## Default Plot
Note that we now generate two plots, one for each smoothed predictor.
```{r}
oldpar <- par(mfrow = c(1,2))
plot(thegam, residuals = TRUE, main="Boring old plots...")
par(oldpar)
```

## Working with Relative Humidity Makes More Sense
Statistically and physically, this model is not all that sensible, since
temperature and dewpoint are highly correlated.  In practice this leads to all
sorts of problems with concurvidity.  Model parameters are likely to be highly
unstable, although predictions are likely less so.

```{r}
cor(the_data$temp, the_data$dewpoint)
```

A better model would be based on temperature and relative humidity.  While
relative humidity can be calculated from temperature and dew point, it is less 
correlated with temperature.

I grabbed this formula off the internet, so I have no idea if it is correct....

```{r}
the_data <- the_data %>%
mutate(RH = 100 * (exp(17.625 * dewpoint /(243.04 + dewpoint)) /
                     exp(17.625 * temp/(243.04 + temp))))
cor(the_data$temp, the_data$RH)
```

## Revised Model
```{r}
thegam2 <- gam(o3 ~ s(temp, k = 5) +s(RH, k = 5), data = the_data)
```

# Default Plot
Note that we now generate two plots, one for each smoothed predictor.
```{r}
oldpar <- par(mfrow = c(1,2))
plot(thegam2, residuals = TRUE, main="Boring old plots...")
par(oldpar)
```

We run into a few statistical issues if we simply follow the approach used
before. This is because it's not clear WHICH predicted values to plot on
the Y axis of our plots. 

The most obvious approach is to to do just what we did before, and plot 
predictions along one variable, but how do we represent the other variables in
the model?  The simplest approach is to fix all other predictors at some
reference value, often a mean or median. 

Note that this approach is not going to work for GAM models that include factors
among the linear predictors because it's generally senseless to calculate an
"average" of factors.  You could work around this problem by selecting a
reference level for factors or calculating predictions for all factors and
averaging them.  That starts to get close the the idea behind calculating 
estimated marginal means. We  should consider using `emmeans()` here instead of
`predict()`.

A nice discussion of related issues is provided [here](https://strengejacke.github.io/ggeffects/articles/introduction_marginal_effects.html)

## Conditional Predictions 
(In other words, predictions with all other predictors fixed, using "predict")

Here, I run through the logic for only one of the conditional effects.  We would
have to repeat this for multiple predictors in the context of our complex GAMs.

### Create prediction data frame
```{r}
t <- data.frame(temp = seq(min(the_data$temp), max(the_data$temp), length = 100),
                RH = mean(the_data$RH, na.rm = TRUE))


p1 <-  predict(
        thegam2,
      type    = "terms",
      newdata = t,
      se.fit  = TRUE
    )
```

Note that now p1 is a LIST with two array components.  

```{r}
class(p1)
names(p1)
class(p1$fit)
dimnames(p1$fit)[2]
```
We need to convert from that format to something slightly easier to work with, 
like a data frame.

Simple use of "as_tibble() does not quite do what we want. It reads in the
two arrays, but does not fully flatten them. (Each Array is a separate item
in the Tibble). Besides, we only want the values associated with our focal 
variable (here `temp`) since the other predictor never changed.

So, we are better off handling the conversion directly.

### Extract Dimensions
```{r}
thenames <- dimnames(p1$fit)[[2]]
thenames <- sub('s(', '', thenames, fixed = TRUE)
(thenames <- sub(')', '', thenames, fixed = TRUE))
(nvars <- length(thenames))
(l <- length(p1$fit)/nvars)
```
### Construct Preditions Tibble
```{r}
p1.1 <- tibble( fit = p1$fit[1:l],
                se.fit = p1$se.fit[1:l],
                temp = t$temp)
```

Now find our background values, just like we did before.  Note that we have to
select which predictor we want.

The way the `term` predictions are calculated, `pred` is a two column array. We
want the first column which we access with a numeric index, rather than by name.
(We could have converted `pred` to a data frame to avoid that....).

### Construct Background Residuals Tibble
```{r}
pred <- predict(thegam2, type = "terms")
background <-  pred[,1] + residuals(thegam2)
attributes(background) <- NULL
background <- tibble(temp = the_data$temp, 
                     background = background, 
                     raw = the_data$o3)
head(background)
```

## Build the Plot
```{r} 
plt <- ggplot(p1.1, aes(temp, fit)) +
  geom_ribbon(aes(ymin = fit - 1.96*se.fit, ymax = fit + 1.96*se.fit), 
              color = 'grey', alpha = 0.2, lty = 0) +
  geom_line(lwd = .5)+
  geom_point(data = background, mapping = aes(temp, background ),
             pch = 16, col = rgb(0, 0, 1, 0.25), size = 0.5) +
  geom_rug(data = background, mapping = aes(x = temp, y = NULL)) +
  
 
  xlim(-3, 90) +
  ylim (-20, 30) +
  ggtitle("Ahhh, definitely better") +
  ylab (paste("s(temp,", round(sum(thegam$edf[-1]),2), ")", sep = ""))
plt
```

## Not an Ideal Solution
This is workable, but there are several problems with this approach.  First, we
are using conditional means, not marginal means, and second, this will be
awkward (although not impossible) to code for an arbitrary number of predictors.

(Conditional means are conditioned on one specific value of other variables. 
Marginal means average across all values of other variables, weighting by 
relative abundance).

# An Alternative, 
Another approach is presented
[here](https://stackoverflow.com/questions/59267259/emmeans-for-estimates-from-gams-for-plotting-and-inference-in-r)

The key insight is that much of the functionality we need is contained in the
`ggeffects` package.  The package provides three functions that predict values
generated via `predict()`, `emmeans()`, or `effects::Effects()` (which I have 
never used). The output is designed to feed into `ggplot()`, with consistent
naming conventions, etc.

Here, it matters little, but when we turn to our full models, we will need to
use `ggemmeans()` so results are properly marginal to any factors (rather than
conditioned over them).

In its simplest form, usage is similar to `emmeans()`. Here I use
`ggpredict()`, which duplicates the analysis we just managed by hand.  The
`plot()` method has fairly intelligent defaults.  Control of the aesthetics is 
some times awkward, but function parameters do give access to many plot details.
Nevertheless, I found I needed to add the rug by hand, and I never found a way 
to independently control the color of the background residual dots.

```{r}
ggp <- ggpredict(thegam2, 'temp')
plt <- plot(ggp, residuals  = TRUE, 
     dot.alpha = 0.25, dot.size = 0.25) +
  geom_rug(aes(y = NULL))
plt
```

The plot() method has lots of customization options.  It generates a 
`ggplot2` plot object. For more control,  we can construct the plot in 
`ggplot()`, but it's not obvious how to add the  related points (raw data or 
residuals) correctly to this plot. Those values need to be generated "by hand" 
from the underlying model, which is not readily available once I have built
a new tibble for the predictions.  That is undoubtedly solvable, but we don't
need to do so, as we will see in a moment.

```{r}
ggplot(ggp, aes(x, predicted)) +
  geom_line(color = 'green') +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.1)  +
  geom_rug(aes(y = NULL))
```

## All Terms
If we just leave out the specification of terms we get back a list of similar
data frames, one for each predictor.

```{r}
ggp <- ggpredict(thegam2)
```

The default `plot()` method handles this great when you want to look at all of
the predictors.

```{r error = TRUE}
plot(ggp, add.data = TRUE, facets = TRUE, colors = c('grey50', 'grey50'),
     dot.size = 0.25, dot.alpha = 0.25) +
  geom_rug(aes(y = NULL)) +
  xlab ('') +
 ylab ('Effects')
```

An alternative is to manually combine the data frames and then use `ggplot` and
the `facet_wrap()` function.  However, as before, we lose information on the 
underlying model, making it more difficult to also plot data or residuals.

```{r}
combodf <- map_df(ggp, bind_rows)
```

```{r}
plt <- plot(combodf, dot.alpha = 0.25, dot.size = 0.25) +
  geom_rug(aes(y = NULL)) +
  facet_wrap(~group, scales = 'free')
plt
```

